const superagent = require('superagent')const cheerio = require('cheerio')const fs = require('fs')const path = require('path')const models = require('./api/models')//定时const cron = require("node-cron");// 1. 引入express// 2。创建app对象，通过语法express（）底层原理http模块的createServer// 3. 路由，语法 app。HTTP请求方式（路径，回调函数）// 4. 启动服务监听端口//mongo post get请求无法接收req.body 需要添加bodyParserconst bodyParser = require('body-parser')const express = require('express')//跨域问题 使用这个模块可以实现跨域功能const cors = require('cors');const app = express()app.use(bodyParser.urlencoded({extended: false}))const multer = require('multer')//const koaStatic = require('koa-static')app.use(bodyParser.json())app.use(cors());//nodejs 做为服务器，在传输内容或者上传文件时，系统默认大小为100kb 调整系统限制为2Mapp.use(bodyParser.json({limit:'100mb'}));app.use(bodyParser.urlencoded({ limit:'100mb', extended: true }));const upload = multer({	storage: multer.diskStorage({		//设置文件存储位置		destination: function (req, file, cb) {			let dir = "./uploads" //图片存储的目录			//判断目录是否存在，没有则创建			if (!fs.existsSync(dir)) {				fs.mkdirSync(dir, {recursive: true});			}			//dir就是上传文件存放的目录			cb(null, dir);		},		//设置文件名称		filename: function (req, file, cb) {			// 取无后缀的文件名			let ex_name =  file.originalname.split('.')[0]			//防止文件名重复，为文件名加上时间戳			let fileName = ex_name + '-' + Date.now() + path.extname(file.originalname);			//fileName就是上传文件的文件名			cb(null, fileName);		}	})})const {	insertData,	clearCollections,	findData,	create,	getHref,	deleteData,	updateData,	fuzzyQuery,} = require('./api/utils')const {	caseListModel,	caseOutsideListModel,	summaryDataInModel,	summaryDataOutModel,	globalListModel,	topAddCountryModel,	topOverseasInputModel,	asymptomaticTopProvinceModel,	newAddTopProvinceModel,	allForeignTrendModel,	trendModel,	articleModel,	spiderArticleModel,	userModel,	reportModel} = modelsconst spiderType = [	{		name:'防控指南',		keyWord:'%E9%98%B2%E6%8E%A7%E6%8C%87%E5%8D%97',		type:2	},	{		name:'疫情趋势',		keyWord:'%E7%96%AB%E6%83%85%E8%B6%8B%E5%8A%BF',		type:1	},	{		name:'最新消息',		keyWord:'%E7%96%AB%E6%83%85',		type:0	}	]const urlDetails = `https://voice.baidu.com/act/newpneumonia/newpneumonia`//先清库clearCollections(	caseListModel,	caseOutsideListModel,	summaryDataInModel,	summaryDataOutModel,	globalListModel,	topAddCountryModel,	topOverseasInputModel,	asymptomaticTopProvinceModel,	newAddTopProvinceModel,	allForeignTrendModel,	trendModel,) const spider =async (dataSource)=> {	 let arr = []	const {name,keyWord,type} = dataSource	 const govUrl = `https://a.jiemian.com/index.php?m=search&a=index&msg=${keyWord}&type=&page=`	new Promise((resolve, reject) => {		let i = 1		let timer = setInterval( async ()=>{			//目前只爬取2页的数据			if (i>4){				console.log(`${name}数据已爬取！`)				await fs.writeFile(path.join(__dirname, './article.json'), JSON.stringify(arr), err => {					if (err) throw err				})				arr.forEach(async (item)=>{					let obj = {}					let url = getHref(item)					const start = url.indexOf('article/')+8 //slice截取是从开始位置截取，这里要减去article/的长度					const end = url.indexOf('.html')					obj.articleId = url.slice(start,end)					obj.type = type					obj.show = true					obj.text = item					 let docs =await spiderArticleModel.find({articleId:obj.articleId})					if (docs.length===0){						insertData(obj, spiderArticleModel)					}				})				clearInterval(timer)				resolve()			}			superagent				.get(govUrl+i)				.then(					async res => {						const $ = cheerio.load(res.text, {decodeEntities: false})						$('.news-view').each(function () {							arr.push( $(this).html())						})					})				.catch(err=>console.log(err))			i++		},2000)	})}const init = async ()=>{	superagent		.get(urlDetails)		.then(			async res => {				const $ = cheerio.load(res.text)				let data = $('#captain-config').html()				data = unescape(data.replace(/\\u/g, '%u'))				let useless = data.slice(data.indexOf('"kingData"'), data.indexOf('"trumpet"'))				data = data.split(useless).join("")				data = JSON.parse(data)				await fs.writeFile(path.join(__dirname, './test.json'), JSON.stringify(data), err => {					if (err) throw err				})				//处理最近一段时间的整体数据，组装对象然后存储到数据库				let arr = [], year = '2020.'				let operateData = data.component[0]				for (let i = 0; i < operateData.trend.updateDate.length; i++) {					let obj = {}					if (operateData.trend.updateDate[i] === '12.31') {						year = '2021.'					}					//拼接数据					//时间					obj.updateDate = year + operateData.trend.updateDate[i]					//已确诊					obj.confirmed = operateData.trend.list[0].data[i]					//疑似					obj.unConfirmed = operateData.trend.list[1].data[i]					//治愈					obj.cured = operateData.trend.list[2].data[i]					//死亡					obj.died = operateData.trend.list[3].data[i]					//新增确诊					obj.newConfirmed = operateData.trend.list[4].data[i]					//新增疑似					obj.newUnConfirmed = operateData.trend.list[5].data[i]					//新增治愈					obj.newCured = operateData.trend.list[6].data[i]					//新增死亡					obj.newDied = operateData.trend.list[7].data[i]					//累计境外输入					obj.overseasInput = operateData.trend.list[8].data[i]					//新增境外输入					obj.newOverseasInput = operateData.trend.list[9].data[i]					arr.push(obj)				}				let i = 0				let timer = setInterval(async ()=>{					if (i>spiderType.length-1){						clearInterval(timer)						setTimeout(()=>{console.log('\n\n爬虫数据写入成功！--------------->')},500)					}else {						await spider(spiderType[i])						i++					}				},1000)				await console.log('\n\n爬虫数据写入成功！--------------->')				//将爬虫数据写入数据库				await insertData(operateData.caseList, caseListModel)				await insertData(operateData.caseOutsideList, caseOutsideListModel)				await insertData(operateData.summaryDataIn, summaryDataInModel)				await insertData(operateData.summaryDataOut, summaryDataOutModel)				await insertData(operateData.globalList, globalListModel)				await insertData(operateData.topAddCountry, topAddCountryModel)				await insertData(operateData.topOverseasInput, topOverseasInputModel)				await insertData(operateData.asymptomaticTopProvince, asymptomaticTopProvinceModel)				await insertData(operateData.newAddTopProvince, newAddTopProvinceModel)				await insertData(operateData.allForeignTrend, allForeignTrendModel)				await insertData(arr, trendModel)				await fs.writeFile(path.join(__dirname, './test.json'), JSON.stringify(data), err => {					if (err) throw err				})				// app.get('/',(req,res)=>{				//   //send是express用来响应数据的方法				//   res.send('发送数据')				// })				//添加 process.cwd()当前命令下的目录路径				//省份疫情数据排行				//插入数据				app.post('/insert', create(newAddTopProvinceModel, insertData, 'post'))				//国内数据				app.get('/area/case', create(caseListModel, findData, 'get'))				//国外查询				app.get('/area/caseOutside', create(caseOutsideListModel, findData, 'get'))				//全球数据查询 7大洲				app.get('/area/globalList', create(globalListModel, findData, 'get'))				//新增确诊排行				app.get('/area/newAddTopProvince', create(newAddTopProvinceModel, findData, 'get'))				//境外输入累计确诊省Top10				app.get('/area/topOverseasInput', create(topOverseasInputModel, findData, 'get'))				//国内疫情基本信息查询				app.get('/area/summaryDataIn', create(summaryDataInModel, findData, 'get'))				//国内疫情基本信息查询				app.get('/area/summaryDataOut', create(summaryDataOutModel, findData, 'get'))				//全球新增确诊排行				app.get('/area/topAddCountry', create(topAddCountryModel, findData, 'get'))				//无症状的国内省份排行				app.get('/area/asymptomaticTopProvince', create(asymptomaticTopProvinceModel, findData, 'get'))				//根据时间检索国内疫情状况				app.get('/date', create(trendModel, findData, 'get'))				//爬虫获取的文章数据				app.get('/spiderArticle', create(spiderArticleModel, findData, 'get'))				//爬虫获取的文章详情				app.get('/articleDetails', create(articleModel, spiderArticle, 'get'))				app.get('/article', create(articleModel, spiderArticle, 'get'))				//注册验证				app.get('/register', create(userModel, findData, 'get'))				//登录验证				app.get('/login', create(userModel, findData, 'get'))				//删除文章数据				app.get('/delete', create(spiderArticleModel, deleteData, 'get'))				//新增文章数据				app.post('/article/user', create(articleModel, updateData, 'post'))				//查询个人文章				app.get('/article/personal', create(articleModel, findData, 'get'))				//删除个人文章				app.get('/delete/personal', create(articleModel, deleteData, 'get'))				//删除用户				app.get('/delete/user', create(userModel, deleteData, 'get'))				//审核文章				app.get('/update/personal', create(articleModel, updateData, 'get'))				//显示隐藏系统文章				app.get('/show/system', create(spiderArticleModel, updateData, 'get'))				//修改用户信息				app.get('/update/user', create(userModel, updateData, 'get'))				//获取用户列表				app.get('/user', create(userModel, findData, 'get'))				//设置管理员身份				app.get('/user/admin', create(userModel, updateData, 'get'))				//信息填报入口				app.get('/report', create(reportModel, updateData, 'get'))				//获取高危城市				app.get('/dangerCity/newAdd', create(newAddTopProvinceModel, findData, 'get'))				app.get('/dangerCity/oversea', create(topOverseasInputModel, findData, 'get'))				//查询信息填报记录				app.get('/report/user', create(reportModel, findData, 'get'))				//查询高危人员				app.get('/danger/user', create(reportModel, findData, 'get'))				 	//清除库				app.get('/clear/article', create(spiderArticleModel, clear, 'get'))				//更新所有爬虫数据				app.post('/update/article', create(spiderArticleModel, updateData, 'post'))				//模糊查询关键字				app.get('/fuzzy/spider', create(spiderArticleModel, fuzzyQuery, 'get'))				app.get('/fuzzy/article', create(articleModel, fuzzyQuery, 'get'))				app.get('/fuzzy/report', create(reportModel, fuzzyQuery, 'get'))				//图片上传				app.post('/upload',upload.single("mypic"), function (req, res) {					console.log(req,res)											res.send({							error:0,							data:[								{									isOK:true,									imgPath:req.file.path, //文件存储的路径									imgName:req.file.filename								}							]						})				})				//图片获取				app.get('/preview/:key',cors() , (req, res) => {					res.sendFile(`/uploads/${req.params.key}`, {						root: __dirname,						headers: {							'Content-Type': 'image/jpge',						}					}, (error) => {						console.log(error)					})				})				app.listen(3000, () => {					console.log('\n\n服务器已启动!==========>\n\n')				})			}		)		.catch(err => {			throw err		})} spiderArticle = async (collections,query={})=>{	try {		const {url,title,text,date,articleId,id,type} = query		console.log(query)		if (!url) return		//如果这条数据存在。则跳过		let search = {}		if (id) search.unique = id		if (articleId) search.unique = articleId		let docs = await articleModel.find(search)		console.log(docs,'docs')		if (docs.length>0){			return docs		}else {			let result	= await superagent				.get(url)				.then(async res=>{					const $ = cheerio.load(res.text,{decodeEntities: false})					let obj = {textContent:[]}					obj.textHeader = $('.article-header h1').text()					obj.img = $('.article-img').html()					console.log(obj.img)					obj.textDate = $('.date').text()					$('.article-content p').each(function () {						obj.textContent.push($(this).html())					//	obj.textContent.push($(this).text())					})					$('.img-focus').each(function () {						obj.textContent.push($(this).html())						//	obj.textContent.push($(this).text())					})					obj.url = url					obj.title = title					obj.text = text					obj.date = date					obj.unique = id || articleId					obj.type = type					//将完整的数据写入数据库					await insertData(obj,articleModel)					return obj				})			console.log(result,'===')			return result		}	}	catch (e) {		console.log(e)	}}const clear = async (collections,query)=>{await clearCollections(spiderArticleModel)let result =await collections.find({})	return result}//定时爬取cron.schedule("* 9 * * *", async function() {await 	init()});module.exports = {	init}